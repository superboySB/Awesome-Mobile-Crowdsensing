# Copyright (c) 2021, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root
# or https://opensource.org/licenses/BSD-3-Clause

# Default trainer, policy and saving configurations

# Default trainer settings
trainer:
    num_gpus: 1 # number of GPU devices used for (distributed) training
    num_envs: 10 # number of environment replicas
    num_episodes: 10000 # number of episodes to run the training for. Can be arbitrarily high!
    train_batch_size: 10000 # total batch size used for training per iteration (across all the environments)
    env_backend: "pycuda" # environment backend, pycuda or numba

# Default policy network settings
policy:
    to_train: False # flag indicating whether the model needs to be trained
    algorithm: "A2C" # algorithm used to train the policy
    vf_loss_coeff: 0.01 # loss coefficient schedule for the value function loss
    entropy_coeff: 0.05 # loss coefficient schedule for the entropy loss
    clip_grad_norm: True # flag indicating whether to clip the gradient norm or not
    max_grad_norm: 0.5 # when clip_grad_norm is True, the clip level
    normalize_advantage: False # flag indicating whether to normalize advantage or not
    normalize_return: False # flag indicating whether to normalize return or not
    clip_param: 0.01 # clip param for PPO
    gamma: 0.98 # discount factor
    lr: 0.0001 # learning rate
    model: # policy model settings
        type: "fully_connected" # model type
        fc_dims: [64, 64] # dimension(s) of the fully connected layers as a list
        model_ckpt_filepath: "" # filepath (used to restore a previously saved model)

# Default checkpoint saving setting
saving:
    metrics_log_freq: 100 # how often (in iterations) to log (and print) the metrics
    model_params_save_freq: 1000 # how often (in iterations) to save the model parameters
    basedir: "/tmp" # base folder used for saving
    name: "default" # experiment name
    tag: "experiment" # experiment tag
