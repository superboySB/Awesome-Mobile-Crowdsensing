{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021, salesforce.com, inc.\\\n",
    "All rights reserved.\\\n",
    "SPDX-License-Identifier: BSD-3-Clause\\\n",
    "For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get started quickly with end-to-end multi-agent RL using WarpDrive! This shows a basic example to create a simple multi-agent Tag environment and get training. For more configuration options and indepth explanations, check out the other tutorials and source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this notebook on [Colab](http://colab.research.google.com/github/salesforce/warp-drive/blob/master/tutorials/simple-end-to-end-example.ipynb)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ PLEASE NOTE:\n",
    "This notebook runs on a GPU runtime.\\\n",
    "If running on Colab, choose Runtime > Change runtime type from the menu, then select `GPU` in the 'Hardware accelerator' dropdown menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install the warp_drive package using\n",
    "\n",
    "- the pip package manager, OR\n",
    "- by cloning the warp_drive package and installing the requirements.\n",
    "\n",
    "We will install the latest version of WarpDrive using the pip package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"rl-warp-drive>=2.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.device_count() > 0, \"This notebook needs a GPU to run!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_envs.tag_continuous.tag_continuous import TagContinuous\n",
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logger level e.g., DEBUG, INFO, WARNING, ERROR\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment, Training, and Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a set of run configurations for your experiments.\n",
    "# Note: these override some of the default configurations in 'warp_drive/training/run_configs/default_configs.yaml'.\n",
    "run_config = dict(\n",
    "    name=\"tag_continuous\",\n",
    "    # Environment settings\n",
    "    env=dict(\n",
    "        num_taggers=5,\n",
    "        num_runners=20,\n",
    "        episode_length=100,\n",
    "        seed=1234,\n",
    "        use_full_observation=False,\n",
    "        num_other_agents_observed=10,\n",
    "        tagging_distance=0.02,\n",
    "    ),\n",
    "    # Trainer settings\n",
    "    trainer=dict(\n",
    "        num_envs=100,  # number of environment replicas (number of GPU blocks used)\n",
    "        train_batch_size=10000,  # total batch size used for training per iteration (across all the environments)\n",
    "        num_episodes=5000,  # total number of episodes to run the training for (can be arbitrarily high!)\n",
    "    ),\n",
    "    # Policy network settings\n",
    "    policy=dict(\n",
    "        runner=dict(\n",
    "            to_train=True,  # flag indicating whether the model needs to be trained\n",
    "            algorithm=\"A2C\",  # algorithm used to train the policy\n",
    "            gamma=0.98,  # discount rate\n",
    "            lr=0.005,  # learning rate\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),  # policy model settings\n",
    "        ),\n",
    "        tagger=dict(\n",
    "            to_train=True,\n",
    "            algorithm=\"A2C\",\n",
    "            gamma=0.98,\n",
    "            lr=0.002,\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    # Checkpoint saving setting\n",
    "    saving=dict(\n",
    "        metrics_log_freq=10,  # how often (in iterations) to print the metrics\n",
    "        model_params_save_freq=5000,  # how often (in iterations) to save the model parameters\n",
    "        basedir=\"/tmp\",  # base folder used for saving\n",
    "        name=\"continuous_tag\",  # experiment name\n",
    "        tag=\"example\",  # experiment tag\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapped environment object via the EnvWrapper\n",
    "# Ensure that env_backend is set to be \"pycuda\" or \"numba\" (in order to run on the GPU)\n",
    "env_wrapper = EnvWrapper(\n",
    "    TagContinuous(**run_config[\"env\"]),\n",
    "    num_envs=run_config[\"trainer\"][\"num_envs\"],\n",
    "    env_backend='pycuda',\n",
    ")\n",
    "\n",
    "# Agents can share policy models: this dictionary maps policy model names to agent ids.\n",
    "policy_tag_to_agent_id_map = {\n",
    "    \"tagger\": list(env_wrapper.env.taggers),\n",
    "    \"runner\": list(env_wrapper.env.runners),\n",
    "}\n",
    "\n",
    "# Create the trainer object\n",
    "trainer = Trainer(\n",
    "    env_wrapper=env_wrapper,\n",
    "    config=run_config,\n",
    "    policy_tag_to_agent_id_map=policy_tag_to_agent_id_map,\n",
    ")\n",
    "\n",
    "# Perform training!\n",
    "trainer.train()\n",
    "\n",
    "# Shut off gracefully\n",
    "trainer.graceful_close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn more and explore our tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, all our tutorials are here:\n",
    "1. [WarpDrive basics(intro and pycuda)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-1.a-warp_drive_basics.ipynb)\n",
    "2. [WarpDrive basics(numba)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-1.b-warp_drive_basics.ipynb)\n",
    "3. [WarpDrive sampler(pycuda)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-2.a-warp_drive_sampler.ipynb)\n",
    "4. [WarpDrive sampler(numba)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-2.b-warp_drive_sampler.ipynb)\n",
    "5. [WarpDrive resetter and logger](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-3-warp_drive_reset_and_log.ipynb)\n",
    "6. [Create custom environments (pycuda)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-4.a-create_custom_environments_pycuda.md)\n",
    "7. [Create custom environments (numba)](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-4.b-create_custom_environments_numba.md)\n",
    "8. [Training with WarpDrive](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-5-training_with_warp_drive.ipynb)\n",
    "9. [Scaling Up training with WarpDrive](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-6-scaling_up_training_with_warp_drive.md)\n",
    "10. [Training with WarpDrive + Pytorch Lightning](https://github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-7-training_with_warp_drive_and_pytorch_lightning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
